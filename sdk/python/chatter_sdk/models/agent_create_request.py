
"""
    Chatter API

    Advanced AI Chatbot Backend API Platform

    The version of the OpenAPI document: 0.1.0
    Contact: support@chatter.ai
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar
from typing import Annotated
from chatter_sdk.models.agent_capability import AgentCapability
from chatter_sdk.models.agent_type import AgentType
from typing import Self

class AgentCreateRequest(BaseModel):
    """
    Request schema for creating an agent.
    """ # noqa: E501
    name: StrictStr = Field(description="Agent name")
    description: StrictStr = Field(description="Agent description")
    agent_type: AgentType
    system_prompt: StrictStr = Field(description="System prompt for the agent")
    personality_traits: list[StrictStr] | None = Field(default=None, description="Agent personality traits")
    knowledge_domains: list[StrictStr] | None = Field(default=None, description="Knowledge domains")
    response_style: StrictStr | None = Field(default='professional', description="Response style")
    capabilities: list[AgentCapability] | None = Field(default=None, description="Agent capabilities")
    available_tools: list[StrictStr] | None = Field(default=None, description="Available tools")
    primary_llm: StrictStr | None = Field(default='openai', description="Primary LLM provider")
    fallback_llm: StrictStr | None = Field(default='anthropic', description="Fallback LLM provider")
    temperature: Annotated[float, Field(le=2.0, strict=True, ge=0.0)] | Annotated[int, Field(le=2, strict=True, ge=0)] | None = Field(default=0.7, description="Temperature for responses")
    max_tokens: Annotated[int, Field(le=32000, strict=True, ge=1)] | None = Field(default=4096, description="Maximum tokens")
    max_conversation_length: Annotated[int, Field(le=1000, strict=True, ge=1)] | None = Field(default=50, description="Maximum conversation length")
    context_window_size: Annotated[int, Field(le=32000, strict=True, ge=100)] | None = Field(default=4000, description="Context window size")
    response_timeout: Annotated[int, Field(le=300, strict=True, ge=1)] | None = Field(default=30, description="Response timeout in seconds")
    learning_enabled: StrictBool | None = Field(default=True, description="Enable learning from feedback")
    feedback_weight: Annotated[float, Field(le=1.0, strict=True, ge=0.0)] | Annotated[int, Field(le=1, strict=True, ge=0)] | None = Field(default=0.1, description="Weight for feedback learning")
    adaptation_threshold: Annotated[float, Field(le=1.0, strict=True, ge=0.0)] | Annotated[int, Field(le=1, strict=True, ge=0)] | None = Field(default=0.8, description="Adaptation threshold")
    tags: list[StrictStr] | None = Field(default=None, description="Agent tags")
    metadata: dict[str, Any] | None = Field(default=None, description="Additional metadata")
    __properties: ClassVar[list[str]] = ["name", "description", "agent_type", "system_prompt", "personality_traits", "knowledge_domains", "response_style", "capabilities", "available_tools", "primary_llm", "fallback_llm", "temperature", "max_tokens", "max_conversation_length", "context_window_size", "response_timeout", "learning_enabled", "feedback_weight", "adaptation_threshold", "tags", "metadata"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self | None:
        """Create an instance of AgentCreateRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: set[str] = set()

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: dict[str, Any] | None) -> Self | None:
        """Create an instance of AgentCreateRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "name": obj.get("name"),
            "description": obj.get("description"),
            "agent_type": obj.get("agent_type"),
            "system_prompt": obj.get("system_prompt"),
            "personality_traits": obj.get("personality_traits"),
            "knowledge_domains": obj.get("knowledge_domains"),
            "response_style": obj.get("response_style") if obj.get("response_style") is not None else 'professional',
            "capabilities": obj.get("capabilities"),
            "available_tools": obj.get("available_tools"),
            "primary_llm": obj.get("primary_llm") if obj.get("primary_llm") is not None else 'openai',
            "fallback_llm": obj.get("fallback_llm") if obj.get("fallback_llm") is not None else 'anthropic',
            "temperature": obj.get("temperature") if obj.get("temperature") is not None else 0.7,
            "max_tokens": obj.get("max_tokens") if obj.get("max_tokens") is not None else 4096,
            "max_conversation_length": obj.get("max_conversation_length") if obj.get("max_conversation_length") is not None else 50,
            "context_window_size": obj.get("context_window_size") if obj.get("context_window_size") is not None else 4000,
            "response_timeout": obj.get("response_timeout") if obj.get("response_timeout") is not None else 30,
            "learning_enabled": obj.get("learning_enabled") if obj.get("learning_enabled") is not None else True,
            "feedback_weight": obj.get("feedback_weight") if obj.get("feedback_weight") is not None else 0.1,
            "adaptation_threshold": obj.get("adaptation_threshold") if obj.get("adaptation_threshold") is not None else 0.8,
            "tags": obj.get("tags"),
            "metadata": obj.get("metadata")
        })
        return _obj


