"""
Chatter API

Advanced AI Chatbot Backend API Platform

The version of the OpenAPI document: 0.1.0
Contact: support@chatter.ai
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501

from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from typing import Annotated, Any, ClassVar, Self

from chatter_sdk.models.profile_type import ProfileType
from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    StrictBool,
    StrictFloat,
    StrictInt,
    StrictStr,
)


class ProfileCreate(BaseModel):
    """
    Schema for creating a profile.
    """  # noqa: E501

    name: Annotated[
        str, Field(min_length=1, strict=True, max_length=255)
    ] = Field(description="Profile name")
    description: (
        Annotated[str, Field(strict=True, max_length=2000)] | None
    ) = None
    profile_type: ProfileType | None = None
    llm_provider: Annotated[
        str, Field(min_length=1, strict=True, max_length=50)
    ] = Field(description="LLM provider (openai, anthropic, etc.)")
    llm_model: Annotated[
        str, Field(min_length=1, strict=True, max_length=100)
    ] = Field(description="LLM model name")
    temperature: (
        Annotated[float, Field(le=2.0, strict=True, ge=0.0)]
        | Annotated[int, Field(le=2, strict=True, ge=0)]
        | None
    ) = Field(default=0.7, description="Temperature for generation")
    top_p: (
        Annotated[float, Field(le=1.0, strict=True, ge=0.0)]
        | Annotated[int, Field(le=1, strict=True, ge=0)]
        | None
    ) = None
    top_k: Annotated[int, Field(le=1000, strict=True, ge=1)] | None = (
        None
    )
    max_tokens: (
        Annotated[int, Field(le=100000, strict=True, ge=1)] | None
    ) = Field(default=4096, description="Maximum tokens to generate")
    presence_penalty: (
        Annotated[float, Field(le=2.0, strict=True, ge=-2.0)]
        | Annotated[int, Field(le=2, strict=True, ge=-2)]
        | None
    ) = None
    frequency_penalty: (
        Annotated[float, Field(le=2.0, strict=True, ge=-2.0)]
        | Annotated[int, Field(le=2, strict=True, ge=-2)]
        | None
    ) = None
    context_window: (
        Annotated[int, Field(le=200000, strict=True, ge=1)] | None
    ) = Field(default=4096, description="Context window size")
    system_prompt: (
        Annotated[str, Field(strict=True, max_length=10000)] | None
    ) = None
    memory_enabled: StrictBool | None = Field(
        default=True, description="Enable conversation memory"
    )
    memory_strategy: (
        Annotated[str, Field(strict=True, max_length=50)] | None
    ) = None
    enable_retrieval: StrictBool | None = Field(
        default=False, description="Enable document retrieval"
    )
    retrieval_limit: (
        Annotated[int, Field(le=50, strict=True, ge=1)] | None
    ) = Field(default=5, description="Number of documents to retrieve")
    retrieval_score_threshold: (
        Annotated[float, Field(le=1.0, strict=True, ge=0.0)]
        | Annotated[int, Field(le=1, strict=True, ge=0)]
        | None
    ) = Field(default=0.7, description="Minimum retrieval score")
    enable_tools: StrictBool | None = Field(
        default=False, description="Enable tool calling"
    )
    available_tools: (
        Annotated[list[StrictStr], Field(max_length=20)] | None
    ) = None
    tool_choice: (
        Annotated[str, Field(strict=True, max_length=50)] | None
    ) = None
    content_filter_enabled: StrictBool | None = Field(
        default=True, description="Enable content filtering"
    )
    safety_level: (
        Annotated[str, Field(strict=True, max_length=20)] | None
    ) = None
    response_format: (
        Annotated[str, Field(strict=True, max_length=20)] | None
    ) = None
    stream_response: StrictBool | None = Field(
        default=True, description="Enable streaming responses"
    )
    seed: (
        Annotated[int, Field(le=2147483647, strict=True, ge=0)] | None
    ) = None
    stop_sequences: (
        Annotated[list[StrictStr], Field(max_length=10)] | None
    ) = None
    logit_bias: dict[str, StrictFloat | StrictInt] | None = None
    embedding_provider: (
        Annotated[str, Field(strict=True, max_length=50)] | None
    ) = None
    embedding_model: (
        Annotated[str, Field(strict=True, max_length=100)] | None
    ) = None
    is_public: StrictBool | None = Field(
        default=False, description="Whether profile is public"
    )
    tags: Annotated[list[StrictStr], Field(max_length=10)] | None = None
    extra_metadata: dict[str, Any] | None = None
    __properties: ClassVar[list[str]] = [
        "name",
        "description",
        "profile_type",
        "llm_provider",
        "llm_model",
        "temperature",
        "top_p",
        "top_k",
        "max_tokens",
        "presence_penalty",
        "frequency_penalty",
        "context_window",
        "system_prompt",
        "memory_enabled",
        "memory_strategy",
        "enable_retrieval",
        "retrieval_limit",
        "retrieval_score_threshold",
        "enable_tools",
        "available_tools",
        "tool_choice",
        "content_filter_enabled",
        "safety_level",
        "response_format",
        "stream_response",
        "seed",
        "stop_sequences",
        "logit_bias",
        "embedding_provider",
        "embedding_model",
        "is_public",
        "tags",
        "extra_metadata",
    ]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self | None:
        """Create an instance of ProfileCreate from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: set[str] = set()

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # set to None if description (nullable) is None
        # and model_fields_set contains the field
        if (
            self.description is None
            and "description" in self.model_fields_set
        ):
            _dict['description'] = None

        # set to None if top_p (nullable) is None
        # and model_fields_set contains the field
        if self.top_p is None and "top_p" in self.model_fields_set:
            _dict['top_p'] = None

        # set to None if top_k (nullable) is None
        # and model_fields_set contains the field
        if self.top_k is None and "top_k" in self.model_fields_set:
            _dict['top_k'] = None

        # set to None if presence_penalty (nullable) is None
        # and model_fields_set contains the field
        if (
            self.presence_penalty is None
            and "presence_penalty" in self.model_fields_set
        ):
            _dict['presence_penalty'] = None

        # set to None if frequency_penalty (nullable) is None
        # and model_fields_set contains the field
        if (
            self.frequency_penalty is None
            and "frequency_penalty" in self.model_fields_set
        ):
            _dict['frequency_penalty'] = None

        # set to None if system_prompt (nullable) is None
        # and model_fields_set contains the field
        if (
            self.system_prompt is None
            and "system_prompt" in self.model_fields_set
        ):
            _dict['system_prompt'] = None

        # set to None if memory_strategy (nullable) is None
        # and model_fields_set contains the field
        if (
            self.memory_strategy is None
            and "memory_strategy" in self.model_fields_set
        ):
            _dict['memory_strategy'] = None

        # set to None if available_tools (nullable) is None
        # and model_fields_set contains the field
        if (
            self.available_tools is None
            and "available_tools" in self.model_fields_set
        ):
            _dict['available_tools'] = None

        # set to None if tool_choice (nullable) is None
        # and model_fields_set contains the field
        if (
            self.tool_choice is None
            and "tool_choice" in self.model_fields_set
        ):
            _dict['tool_choice'] = None

        # set to None if safety_level (nullable) is None
        # and model_fields_set contains the field
        if (
            self.safety_level is None
            and "safety_level" in self.model_fields_set
        ):
            _dict['safety_level'] = None

        # set to None if response_format (nullable) is None
        # and model_fields_set contains the field
        if (
            self.response_format is None
            and "response_format" in self.model_fields_set
        ):
            _dict['response_format'] = None

        # set to None if seed (nullable) is None
        # and model_fields_set contains the field
        if self.seed is None and "seed" in self.model_fields_set:
            _dict['seed'] = None

        # set to None if stop_sequences (nullable) is None
        # and model_fields_set contains the field
        if (
            self.stop_sequences is None
            and "stop_sequences" in self.model_fields_set
        ):
            _dict['stop_sequences'] = None

        # set to None if logit_bias (nullable) is None
        # and model_fields_set contains the field
        if (
            self.logit_bias is None
            and "logit_bias" in self.model_fields_set
        ):
            _dict['logit_bias'] = None

        # set to None if embedding_provider (nullable) is None
        # and model_fields_set contains the field
        if (
            self.embedding_provider is None
            and "embedding_provider" in self.model_fields_set
        ):
            _dict['embedding_provider'] = None

        # set to None if embedding_model (nullable) is None
        # and model_fields_set contains the field
        if (
            self.embedding_model is None
            and "embedding_model" in self.model_fields_set
        ):
            _dict['embedding_model'] = None

        # set to None if tags (nullable) is None
        # and model_fields_set contains the field
        if self.tags is None and "tags" in self.model_fields_set:
            _dict['tags'] = None

        # set to None if extra_metadata (nullable) is None
        # and model_fields_set contains the field
        if (
            self.extra_metadata is None
            and "extra_metadata" in self.model_fields_set
        ):
            _dict['extra_metadata'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: dict[str, Any] | None) -> Self | None:
        """Create an instance of ProfileCreate from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "name": obj.get("name"),
                "description": obj.get("description"),
                "profile_type": obj.get("profile_type"),
                "llm_provider": obj.get("llm_provider"),
                "llm_model": obj.get("llm_model"),
                "temperature": (
                    obj.get("temperature")
                    if obj.get("temperature") is not None
                    else 0.7
                ),
                "top_p": obj.get("top_p"),
                "top_k": obj.get("top_k"),
                "max_tokens": (
                    obj.get("max_tokens")
                    if obj.get("max_tokens") is not None
                    else 4096
                ),
                "presence_penalty": obj.get("presence_penalty"),
                "frequency_penalty": obj.get("frequency_penalty"),
                "context_window": (
                    obj.get("context_window")
                    if obj.get("context_window") is not None
                    else 4096
                ),
                "system_prompt": obj.get("system_prompt"),
                "memory_enabled": (
                    obj.get("memory_enabled")
                    if obj.get("memory_enabled") is not None
                    else True
                ),
                "memory_strategy": obj.get("memory_strategy"),
                "enable_retrieval": (
                    obj.get("enable_retrieval")
                    if obj.get("enable_retrieval") is not None
                    else False
                ),
                "retrieval_limit": (
                    obj.get("retrieval_limit")
                    if obj.get("retrieval_limit") is not None
                    else 5
                ),
                "retrieval_score_threshold": (
                    obj.get("retrieval_score_threshold")
                    if obj.get("retrieval_score_threshold") is not None
                    else 0.7
                ),
                "enable_tools": (
                    obj.get("enable_tools")
                    if obj.get("enable_tools") is not None
                    else False
                ),
                "available_tools": obj.get("available_tools"),
                "tool_choice": obj.get("tool_choice"),
                "content_filter_enabled": (
                    obj.get("content_filter_enabled")
                    if obj.get("content_filter_enabled") is not None
                    else True
                ),
                "safety_level": obj.get("safety_level"),
                "response_format": obj.get("response_format"),
                "stream_response": (
                    obj.get("stream_response")
                    if obj.get("stream_response") is not None
                    else True
                ),
                "seed": obj.get("seed"),
                "stop_sequences": obj.get("stop_sequences"),
                "logit_bias": obj.get("logit_bias"),
                "embedding_provider": obj.get("embedding_provider"),
                "embedding_model": obj.get("embedding_model"),
                "is_public": (
                    obj.get("is_public")
                    if obj.get("is_public") is not None
                    else False
                ),
                "tags": obj.get("tags"),
                "extra_metadata": obj.get("extra_metadata"),
            }
        )
        return _obj
