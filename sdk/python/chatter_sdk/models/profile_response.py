# coding: utf-8

"""
    Chatter API

    Advanced AI Chatbot Backend API Platform

    The version of the OpenAPI document: 0.1.0
    Contact: support@chatter.ai
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictFloat, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from chatter_sdk.models.profile_type import ProfileType
from typing import Optional, Set
from typing_extensions import Self

class ProfileResponse(BaseModel):
    """
    Schema for profile response.
    """ # noqa: E501
    name: Annotated[str, Field(min_length=1, strict=True, max_length=255)] = Field(description="Profile name")
    description: Optional[Annotated[str, Field(strict=True, max_length=2000)]] = None
    profile_type: Optional[ProfileType] = None
    llm_provider: Annotated[str, Field(min_length=1, strict=True, max_length=50)] = Field(description="LLM provider (openai, anthropic, etc.)")
    llm_model: Annotated[str, Field(min_length=1, strict=True, max_length=100)] = Field(description="LLM model name")
    temperature: Optional[Union[Annotated[float, Field(le=2.0, strict=True, ge=0.0)], Annotated[int, Field(le=2, strict=True, ge=0)]]] = Field(default=0.7, description="Temperature for generation")
    top_p: Optional[Union[Annotated[float, Field(le=1.0, strict=True, ge=0.0)], Annotated[int, Field(le=1, strict=True, ge=0)]]] = None
    top_k: Optional[Annotated[int, Field(le=1000, strict=True, ge=1)]] = None
    max_tokens: Optional[Annotated[int, Field(le=100000, strict=True, ge=1)]] = Field(default=4096, description="Maximum tokens to generate")
    presence_penalty: Optional[Union[Annotated[float, Field(le=2.0, strict=True, ge=-2.0)], Annotated[int, Field(le=2, strict=True, ge=-2)]]] = None
    frequency_penalty: Optional[Union[Annotated[float, Field(le=2.0, strict=True, ge=-2.0)], Annotated[int, Field(le=2, strict=True, ge=-2)]]] = None
    context_window: Optional[Annotated[int, Field(le=200000, strict=True, ge=1)]] = Field(default=4096, description="Context window size")
    system_prompt: Optional[Annotated[str, Field(strict=True, max_length=10000)]] = None
    memory_enabled: Optional[StrictBool] = Field(default=True, description="Enable conversation memory")
    memory_strategy: Optional[Annotated[str, Field(strict=True, max_length=50)]] = None
    enable_retrieval: Optional[StrictBool] = Field(default=False, description="Enable document retrieval")
    retrieval_limit: Optional[Annotated[int, Field(le=50, strict=True, ge=1)]] = Field(default=5, description="Number of documents to retrieve")
    retrieval_score_threshold: Optional[Union[Annotated[float, Field(le=1.0, strict=True, ge=0.0)], Annotated[int, Field(le=1, strict=True, ge=0)]]] = Field(default=0.7, description="Minimum retrieval score")
    enable_tools: Optional[StrictBool] = Field(default=False, description="Enable tool calling")
    available_tools: Optional[Annotated[List[StrictStr], Field(max_length=20)]] = None
    tool_choice: Optional[Annotated[str, Field(strict=True, max_length=50)]] = None
    content_filter_enabled: Optional[StrictBool] = Field(default=True, description="Enable content filtering")
    safety_level: Optional[Annotated[str, Field(strict=True, max_length=20)]] = None
    response_format: Optional[Annotated[str, Field(strict=True, max_length=20)]] = None
    stream_response: Optional[StrictBool] = Field(default=True, description="Enable streaming responses")
    seed: Optional[Annotated[int, Field(le=2147483647, strict=True, ge=0)]] = None
    stop_sequences: Optional[Annotated[List[StrictStr], Field(max_length=10)]] = None
    logit_bias: Optional[Dict[str, Union[StrictFloat, StrictInt]]] = None
    embedding_provider: Optional[Annotated[str, Field(strict=True, max_length=50)]] = None
    embedding_model: Optional[Annotated[str, Field(strict=True, max_length=100)]] = None
    is_public: Optional[StrictBool] = Field(default=False, description="Whether profile is public")
    tags: Optional[Annotated[List[StrictStr], Field(max_length=10)]] = None
    extra_metadata: Optional[Dict[str, Any]] = None
    id: StrictStr = Field(description="Profile ID")
    owner_id: StrictStr = Field(description="Owner user ID")
    usage_count: StrictInt = Field(description="Number of times used")
    total_tokens_used: StrictInt = Field(description="Total tokens used")
    total_cost: Union[StrictFloat, StrictInt] = Field(description="Total cost incurred")
    last_used_at: Optional[datetime] = None
    created_at: datetime = Field(description="Creation time")
    updated_at: datetime = Field(description="Last update time")
    __properties: ClassVar[List[str]] = ["name", "description", "profile_type", "llm_provider", "llm_model", "temperature", "top_p", "top_k", "max_tokens", "presence_penalty", "frequency_penalty", "context_window", "system_prompt", "memory_enabled", "memory_strategy", "enable_retrieval", "retrieval_limit", "retrieval_score_threshold", "enable_tools", "available_tools", "tool_choice", "content_filter_enabled", "safety_level", "response_format", "stream_response", "seed", "stop_sequences", "logit_bias", "embedding_provider", "embedding_model", "is_public", "tags", "extra_metadata", "id", "owner_id", "usage_count", "total_tokens_used", "total_cost", "last_used_at", "created_at", "updated_at"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ProfileResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # set to None if description (nullable) is None
        # and model_fields_set contains the field
        if self.description is None and "description" in self.model_fields_set:
            _dict['description'] = None

        # set to None if top_p (nullable) is None
        # and model_fields_set contains the field
        if self.top_p is None and "top_p" in self.model_fields_set:
            _dict['top_p'] = None

        # set to None if top_k (nullable) is None
        # and model_fields_set contains the field
        if self.top_k is None and "top_k" in self.model_fields_set:
            _dict['top_k'] = None

        # set to None if presence_penalty (nullable) is None
        # and model_fields_set contains the field
        if self.presence_penalty is None and "presence_penalty" in self.model_fields_set:
            _dict['presence_penalty'] = None

        # set to None if frequency_penalty (nullable) is None
        # and model_fields_set contains the field
        if self.frequency_penalty is None and "frequency_penalty" in self.model_fields_set:
            _dict['frequency_penalty'] = None

        # set to None if system_prompt (nullable) is None
        # and model_fields_set contains the field
        if self.system_prompt is None and "system_prompt" in self.model_fields_set:
            _dict['system_prompt'] = None

        # set to None if memory_strategy (nullable) is None
        # and model_fields_set contains the field
        if self.memory_strategy is None and "memory_strategy" in self.model_fields_set:
            _dict['memory_strategy'] = None

        # set to None if available_tools (nullable) is None
        # and model_fields_set contains the field
        if self.available_tools is None and "available_tools" in self.model_fields_set:
            _dict['available_tools'] = None

        # set to None if tool_choice (nullable) is None
        # and model_fields_set contains the field
        if self.tool_choice is None and "tool_choice" in self.model_fields_set:
            _dict['tool_choice'] = None

        # set to None if safety_level (nullable) is None
        # and model_fields_set contains the field
        if self.safety_level is None and "safety_level" in self.model_fields_set:
            _dict['safety_level'] = None

        # set to None if response_format (nullable) is None
        # and model_fields_set contains the field
        if self.response_format is None and "response_format" in self.model_fields_set:
            _dict['response_format'] = None

        # set to None if seed (nullable) is None
        # and model_fields_set contains the field
        if self.seed is None and "seed" in self.model_fields_set:
            _dict['seed'] = None

        # set to None if stop_sequences (nullable) is None
        # and model_fields_set contains the field
        if self.stop_sequences is None and "stop_sequences" in self.model_fields_set:
            _dict['stop_sequences'] = None

        # set to None if logit_bias (nullable) is None
        # and model_fields_set contains the field
        if self.logit_bias is None and "logit_bias" in self.model_fields_set:
            _dict['logit_bias'] = None

        # set to None if embedding_provider (nullable) is None
        # and model_fields_set contains the field
        if self.embedding_provider is None and "embedding_provider" in self.model_fields_set:
            _dict['embedding_provider'] = None

        # set to None if embedding_model (nullable) is None
        # and model_fields_set contains the field
        if self.embedding_model is None and "embedding_model" in self.model_fields_set:
            _dict['embedding_model'] = None

        # set to None if tags (nullable) is None
        # and model_fields_set contains the field
        if self.tags is None and "tags" in self.model_fields_set:
            _dict['tags'] = None

        # set to None if extra_metadata (nullable) is None
        # and model_fields_set contains the field
        if self.extra_metadata is None and "extra_metadata" in self.model_fields_set:
            _dict['extra_metadata'] = None

        # set to None if last_used_at (nullable) is None
        # and model_fields_set contains the field
        if self.last_used_at is None and "last_used_at" in self.model_fields_set:
            _dict['last_used_at'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ProfileResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "name": obj.get("name"),
            "description": obj.get("description"),
            "profile_type": obj.get("profile_type"),
            "llm_provider": obj.get("llm_provider"),
            "llm_model": obj.get("llm_model"),
            "temperature": obj.get("temperature") if obj.get("temperature") is not None else 0.7,
            "top_p": obj.get("top_p"),
            "top_k": obj.get("top_k"),
            "max_tokens": obj.get("max_tokens") if obj.get("max_tokens") is not None else 4096,
            "presence_penalty": obj.get("presence_penalty"),
            "frequency_penalty": obj.get("frequency_penalty"),
            "context_window": obj.get("context_window") if obj.get("context_window") is not None else 4096,
            "system_prompt": obj.get("system_prompt"),
            "memory_enabled": obj.get("memory_enabled") if obj.get("memory_enabled") is not None else True,
            "memory_strategy": obj.get("memory_strategy"),
            "enable_retrieval": obj.get("enable_retrieval") if obj.get("enable_retrieval") is not None else False,
            "retrieval_limit": obj.get("retrieval_limit") if obj.get("retrieval_limit") is not None else 5,
            "retrieval_score_threshold": obj.get("retrieval_score_threshold") if obj.get("retrieval_score_threshold") is not None else 0.7,
            "enable_tools": obj.get("enable_tools") if obj.get("enable_tools") is not None else False,
            "available_tools": obj.get("available_tools"),
            "tool_choice": obj.get("tool_choice"),
            "content_filter_enabled": obj.get("content_filter_enabled") if obj.get("content_filter_enabled") is not None else True,
            "safety_level": obj.get("safety_level"),
            "response_format": obj.get("response_format"),
            "stream_response": obj.get("stream_response") if obj.get("stream_response") is not None else True,
            "seed": obj.get("seed"),
            "stop_sequences": obj.get("stop_sequences"),
            "logit_bias": obj.get("logit_bias"),
            "embedding_provider": obj.get("embedding_provider"),
            "embedding_model": obj.get("embedding_model"),
            "is_public": obj.get("is_public") if obj.get("is_public") is not None else False,
            "tags": obj.get("tags"),
            "extra_metadata": obj.get("extra_metadata"),
            "id": obj.get("id"),
            "owner_id": obj.get("owner_id"),
            "usage_count": obj.get("usage_count"),
            "total_tokens_used": obj.get("total_tokens_used"),
            "total_cost": obj.get("total_cost"),
            "last_used_at": obj.get("last_used_at"),
            "created_at": obj.get("created_at"),
            "updated_at": obj.get("updated_at")
        })
        return _obj


