# coding: utf-8

"""
    Chatter API

    Advanced AI Chatbot Backend API Platform

    The version of the OpenAPI document: 0.1.0
    Contact: support@chatter.ai
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt
from typing import Any, ClassVar, Dict, List, Union
from typing import Optional, Set
from typing_extensions import Self

class UsageMetricsResponse(BaseModel):
    """
    Schema for usage metrics response.
    """ # noqa: E501
    total_prompt_tokens: StrictInt = Field(description="Total prompt tokens")
    total_completion_tokens: StrictInt = Field(description="Total completion tokens")
    total_tokens: StrictInt = Field(description="Total tokens used")
    tokens_by_model: Dict[str, StrictInt] = Field(description="Token usage by model")
    tokens_by_provider: Dict[str, StrictInt] = Field(description="Token usage by provider")
    total_cost: Union[StrictFloat, StrictInt] = Field(description="Total cost")
    cost_by_model: Dict[str, Union[StrictFloat, StrictInt]] = Field(description="Cost by model")
    cost_by_provider: Dict[str, Union[StrictFloat, StrictInt]] = Field(description="Cost by provider")
    daily_usage: Dict[str, StrictInt] = Field(description="Daily token usage")
    daily_cost: Dict[str, Union[StrictFloat, StrictInt]] = Field(description="Daily cost")
    avg_response_time: Union[StrictFloat, StrictInt] = Field(description="Average response time")
    response_times_by_model: Dict[str, Union[StrictFloat, StrictInt]] = Field(description="Response times by model")
    active_days: StrictInt = Field(description="Number of active days")
    peak_usage_hour: StrictInt = Field(description="Peak usage hour")
    conversations_per_day: Union[StrictFloat, StrictInt] = Field(description="Average conversations per day")
    __properties: ClassVar[List[str]] = ["total_prompt_tokens", "total_completion_tokens", "total_tokens", "tokens_by_model", "tokens_by_provider", "total_cost", "cost_by_model", "cost_by_provider", "daily_usage", "daily_cost", "avg_response_time", "response_times_by_model", "active_days", "peak_usage_hour", "conversations_per_day"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of UsageMetricsResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of UsageMetricsResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "total_prompt_tokens": obj.get("total_prompt_tokens"),
            "total_completion_tokens": obj.get("total_completion_tokens"),
            "total_tokens": obj.get("total_tokens"),
            "tokens_by_model": obj.get("tokens_by_model"),
            "tokens_by_provider": obj.get("tokens_by_provider"),
            "total_cost": obj.get("total_cost"),
            "cost_by_model": obj.get("cost_by_model"),
            "cost_by_provider": obj.get("cost_by_provider"),
            "daily_usage": obj.get("daily_usage"),
            "daily_cost": obj.get("daily_cost"),
            "avg_response_time": obj.get("avg_response_time"),
            "response_times_by_model": obj.get("response_times_by_model"),
            "active_days": obj.get("active_days"),
            "peak_usage_hour": obj.get("peak_usage_hour"),
            "conversations_per_day": obj.get("conversations_per_day")
        })
        return _obj


