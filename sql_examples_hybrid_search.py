"""
SQL Query Examples for Hybrid Vector Search

This shows the actual SQL queries generated by the hybrid vector search system
to demonstrate how it leverages pgvector indexes optimally.
"""


def show_sql_examples():
    """Show SQL query examples for different search scenarios."""
    
    print("=== Generated SQL Queries ===\n")
    
    print("1. Standard 1536-dimension search (OpenAI embeddings):")
    print("   → Uses 'embedding' column with HNSW index")
    print()
    
    sql_1536 = """
    SELECT *
    FROM document_chunks
    WHERE embedding IS NOT NULL
      AND document_id = ANY($1)  -- Optional document filter
    ORDER BY embedding <=> $2    -- Cosine distance with HNSW index
    LIMIT $3;
    """
    
    print("SQL:")
    print(sql_1536)
    print("Index used: idx_document_chunks_embedding_cosine (HNSW)")
    print("Performance: Fastest (direct indexed search)")
    print()
    
    print("2. Exact dimension match search (768-dim Sentence Transformers):")
    print("   → Uses 'raw_embedding' with dimension filter, falls back to computed_embedding for indexing")
    print()
    
    sql_exact = """
    SELECT *
    FROM document_chunks
    WHERE computed_embedding IS NOT NULL
      AND raw_dim = $1           -- Filter by exact dimension
      AND document_id = ANY($2)  -- Optional document filter
    ORDER BY computed_embedding <=> $3  -- Use computed_embedding for indexing
    LIMIT $4;
    """
    
    print("SQL:")
    print(sql_exact)
    print("Index used: idx_document_chunks_computed_embedding_cosine (HNSW)")
    print("Additional index: idx_document_chunks_raw_dim (B-tree for filtering)")
    print("Performance: Fast (indexed search with dimension filter)")
    print()
    
    print("3. Normalized search for any dimension:")
    print("   → Uses 'computed_embedding' column with automatic normalization")
    print()
    
    sql_computed = """
    SELECT *
    FROM document_chunks
    WHERE computed_embedding IS NOT NULL
      AND document_id = ANY($1)  -- Optional document filter
    ORDER BY computed_embedding <=> $2  -- Normalized query vector
    LIMIT $3;
    """
    
    print("SQL:")
    print(sql_computed)
    print("Index used: idx_document_chunks_computed_embedding_cosine (HNSW)")
    print("Performance: Fast (normalized vectors with full indexing)")
    print()
    
    print("4. Similarity calculation in results:")
    print("   → Cosine similarity computed in Python from indexed results")
    print()
    
    similarity_calc = """
    -- After getting results from indexed search above:
    -- Python calculates actual similarity scores:
    
    import numpy as np
    
    for chunk in results:
        chunk_vec = np.array(chunk.embedding)  # Or appropriate column
        query_vec = np.array(prepared_query)
        
        similarity = np.dot(chunk_vec, query_vec) / (
            np.linalg.norm(chunk_vec) * np.linalg.norm(query_vec)
        )
    """
    
    print(similarity_calc)
    print()
    
    print("=== Index Creation SQL ===\n")
    
    index_sql = """
    -- Vector extension
    CREATE EXTENSION IF NOT EXISTS vector;
    
    -- HNSW indexes for fast vector similarity search
    CREATE INDEX IF NOT EXISTS idx_document_chunks_embedding_cosine
    ON document_chunks USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);
    
    CREATE INDEX IF NOT EXISTS idx_document_chunks_computed_embedding_cosine
    ON document_chunks USING hnsw (computed_embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);
    
    -- B-tree index for dimension filtering
    CREATE INDEX IF NOT EXISTS idx_document_chunks_raw_dim
    ON document_chunks (raw_dim) WHERE raw_dim IS NOT NULL;
    
    -- Analyze for optimal query planning
    ANALYZE document_chunks;
    """
    
    print(index_sql)
    
    print("=== Performance Characteristics ===\n")
    
    performance = [
        {
            "scenario": "1536-dim query → embedding column",
            "index": "HNSW on Vector(1536)",
            "ops": "~1000 QPS",
            "latency": "~1-5ms"
        },
        {
            "scenario": "Any-dim query → computed_embedding",
            "index": "HNSW on Vector(1536)", 
            "ops": "~1000 QPS",
            "latency": "~1-5ms"
        },
        {
            "scenario": "Exact-dim query with filter",
            "index": "HNSW + B-tree filter",
            "ops": "~800 QPS",
            "latency": "~2-8ms"
        },
        {
            "scenario": "Traditional sequential scan",
            "index": "None",
            "ops": "~10 QPS",
            "latency": "~100-1000ms"
        }
    ]
    
    print("┌─────────────────────────────┬─────────────────────┬───────────┬──────────┐")
    print("│ Scenario                    │ Index Type          │ Ops/Sec   │ Latency  │")
    print("├─────────────────────────────┼─────────────────────┼───────────┼──────────┤")
    
    for perf in performance:
        print(f"│ {perf['scenario']:<27} │ {perf['index']:<19} │ {perf['ops']:<9} │ {perf['latency']:<8} │")
    
    print("└─────────────────────────────┴─────────────────────┴───────────┴──────────┘")
    print()
    print("*Approximate values based on pgvector benchmarks with typical workloads")
    
    print("\n=== Key Advantages ===")
    print("✓ Leverages pgvector's optimized HNSW indexes for sub-millisecond search")
    print("✓ Automatic query optimization based on vector dimensions")
    print("✓ Support for multiple embedding models without performance penalty")
    print("✓ Dimension filtering for exact matches when needed")
    print("✓ Full PostgreSQL query optimization and caching benefits")
    print("✓ Scales horizontally with PostgreSQL clustering")


if __name__ == "__main__":
    show_sql_examples()